{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import pickle\n",
    "client = MongoClient()\n",
    "db = client.data_scientist_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.final_profile_details.find({}, {\"assignments\": 0, \"dev_last_worked_ts\": 0,\n",
    "         \"dev_portrait\": 0, \"dev_portrait_100\": 0, \"dev_portrait_32\": 0, \"dev_portrait_50\": 0,\n",
    "          \"dev_timezone\": 0, \"permalink\": 0, \"ag_cny_recno\":0, \"ag_country\":0, \"ag_country_tz\":0,\n",
    "           \"ag_description\": 0, \"ag_logo\": 0, \"ag_name\": 0, \"ag_recent_hours\": 0, \n",
    "           \"ag_total_hours\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_profiles = pd.DataFrame(list(cursor))\n",
    "# drop duplicates\n",
    "ap = all_profiles.drop_duplicates(subset = \"ciphertext\")\n",
    "# remove new line character \n",
    "ap[\"dev_blurb\"] = ap[\"dev_blurb\"].apply(lambda x: x.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73576"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_profiles = ap[\"dev_blurb\"].apply(lambda x: len(x))\n",
    "len(length_profiles[length_profiles > 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most people have a profile of a decent length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"jobs.pkl\", 'r') as picklefile: \n",
    "    jobs = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return all jobs that meet a certain criteria\n",
    "def return_jobs(job_df, duration = \"No Preference\", job_type = \"No Preference\", \n",
    "               workload = \"No Preference\", payment_verification_status = \"No Preference\"):\n",
    "    # get names of all arguments except for job_df\n",
    "    args = locals().keys()\n",
    "    args.remove(\"job_df\")\n",
    "    valid_jobs = job_df\n",
    "    # for every argument entered, limit the dataframe\n",
    "    for restriction in args:\n",
    "        if locals()[restriction] != \"No Preference\":\n",
    "            valid_jobs = valid_jobs[(valid_jobs[restriction] == locals()[restriction])]\n",
    "    return valid_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cosine similarities of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, \n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(jobs[\"snippet\"])\n",
    "similarities = cosine_similarity(tf)\n",
    "np.fill_diagonal(similarities, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35361402919942991"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities[1][473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Looking for someone to do data collection.First project:This will start at the website http://www.signscompanies.comYou will then click on Browse by State, going to each website and collecting as much info as possible  clicking on each web link and collecting from there site Name, Address, Phone and Email address. Putting all that data in .cvs file.First state I need collected is Tennessee. Send sample of 5 shops to get job.Looking for a long time contract for the right person.'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so 1 and 473 look similar, let's check them out\n",
    "jobs[\"snippet\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Looking for Data miner to extract information from website and provide information in organize excel spreadsheet. Website might be membership only...not sure. I have a few different websites...I would like the following data mined from these website organization...-Narrow to Southern California-Contact Name ( Usually the CEO)-Their address-their email address-website address (www.website.com) Provide full URL-when and how long they've been a member There are a few websites. Please provide quote and what kind of information you can scrap. Please message for the website(s) if you would like to test to see if you can pull it off.\""
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[\"snippet\"].iloc[473]len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cosine similarity of job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, \n",
    "                                   stop_words='english')\n",
    "tf_title = tfidf_vectorizer.fit_transform(jobs[\"title\"])\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities_title = cosine_similarity(tf_title)\n",
    "np.fill_diagonal(similarities_title, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2853"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_title[50].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82592272673422917"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_title[50][2853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'SAS Programmer Needed'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[\"title\"].iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Need a SAS programmer'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[\"title\"].iloc[2853]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it's working pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79860"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"highest_degree.pkl\", 'r') as picklefile: \n",
    "    highest_degree = pickle.load(picklefile)\n",
    "len(highest_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.final_profile_details.find({}, {\"dev_blurb\" : 1, \"ciphertext\": 1}) \n",
    "just_blurbs = pd.DataFrame(list(cursor))\n",
    "# drop duplicates\n",
    "just_blurbs = just_blurbs.drop_duplicates(subset = \"ciphertext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "just_blurbs[\"profile_length\"] = just_blurbs[\"dev_blurb\"].apply(lambda x: len(x))\n",
    "just_blurbs[\"dev_blurb\"] = just_blurbs[\"dev_blurb\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "just_blurbs_long = just_blurbs[just_blurbs[\"profile_length\"] > 250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get cosine similarity of a profile and all jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarities(profile_text, jobs):\n",
    "    # get jobs and profile into tfidf\n",
    "    s1 = pd.Series(profile_text)\n",
    "    jobs_and_blurb = s1.append(jobs[\"snippet\"])\n",
    "    tfidf_vectorizer_blurb = TfidfVectorizer(max_df=0.95, min_df=2, \n",
    "                                stop_words='english')\n",
    "    tfidf_blurb =tfidf_vectorizer_blurb.fit_transform(jobs_and_blurb)\n",
    "    profile_tfidf = tfidf_blurb[0]\n",
    "    job_similarities = []\n",
    "    for job in tfidf_blurb[1:]:\n",
    "        job_similarities.append(cosine_similarity(profile_tfidf, job))\n",
    "    return job_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try computing a profile similarity to a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series(just_blurbs_long[\"dev_blurb\"].iloc[100])\n",
    "jobs[\"snippet\"] = jobs[\"snippet\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "jobs[\"snippet\"] = jobs[\"snippet\"].apply(lambda x: x.replace(\"\\u\", \" \"))\n",
    "jobs[\"snippet\"] = jobs[\"snippet\"].apply(lambda x: x.replace(\"\\t\", \" \"))\n",
    "jobs[\"length_jobs\"] = jobs[\"snippet\"].apply(lambda x: len(x))\n",
    "long_jobs = jobs[jobs[\"length_jobs\"] > 150]\n",
    "long_jobs_and_one_blurb = s1.append(long_jobs[\"snippet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "tfidf_vectorizer_blurb = TfidfVectorizer(max_df=0.95, min_df=2, \n",
    "                                stop_words='english')\n",
    "tfidf_blurb = tfidf_vectorizer_blurb.fit_transform(long_jobs_and_one_blurb)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities_blurb_tfidf = cosine_similarity(tfidf_blurb)\n",
    "np.fill_diagonal(similarities_blurb_tfidf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_blurb_tfidf[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22953526481905137"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_blurb[0][537]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skill_match(persons_skills, job_skills = []):\n",
    "    if job_skills == []:\n",
    "        return .2\n",
    "    per_skill_have = float(len([val for val in persons_skills if val in job_skills]))/len(job_skills)\n",
    "    return per_skill_have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_match([\"c+\", \"java\"], [\"java\", \"happy\", \"days\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultimate Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_column(df, col_name):\n",
    "    df[\"demeaned_col\"] = df[col_name].apply(lambda x: x - df[col_name].mean())\n",
    "    range_col = (df[col_name].max() - df[col_name].min())\n",
    "    normed_col = df[\"demeaned_col\"].apply(lambda x: x/range_col)\n",
    "    return normed_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ultimate_matching_algorithm(jobs, profile_text, profile_skills = [], duration = \"No Preference\", job_type = \"No Preference\", \n",
    "workload = \"No Preference\", payment_verification_status = \"No Preference\"):\n",
    "    # select only jobs meeting strict criteria\n",
    "    select_jobs = return_jobs(jobs, duration, job_type, workload, payment_verification_status)\n",
    "    # look for jobs with at least 150 words\n",
    "    select_jobs[\"snippet_length\"] = select_jobs[\"snippet\"].apply(lambda x: len(x))\n",
    "    select_jobs = select_jobs[select_jobs[\"snippet_length\"] > 150]\n",
    "    # add skill match column \n",
    "    select_jobs[\"skill_match\"] = select_jobs[\"skills\"].apply(lambda x: skill_match(profile_skills, x))\n",
    "    # add profile text match column \n",
    "    select_jobs[\"similarity_score\"] = cosine_similarities(profile_text, select_jobs)\n",
    "    # add normalized columns\n",
    "    select_jobs[\"norm_similarity\"] = norm_column(select_jobs, \"similarity_score\")\n",
    "    select_jobs[\"norm_skills\"] = norm_column(select_jobs, \"skill_match\")\n",
    "    #column with combination of profile and skill match, having standardized them\n",
    "    select_jobs[\"skill_and_similarity\"] = select_jobs[\"norm_similarity\"] + .5*select_jobs[\"norm_skills\"]\n",
    "    # drop extra columns\n",
    "    select_jobs = select_jobs.drop([\"profile_length\", \"skill_match\", \"similarity_score\", \"demeaned_col\", \"norm_similarity\", \"norm_skills\"], axis = 1)\n",
    "    # return first 20 jobs\n",
    "    return select_jobs.sort_values(\"skill_and_similarity\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>duration</th>\n",
       "      <th>id</th>\n",
       "      <th>job_type</th>\n",
       "      <th>skills</th>\n",
       "      <th>snippet</th>\n",
       "      <th>title</th>\n",
       "      <th>workload</th>\n",
       "      <th>country</th>\n",
       "      <th>feedback</th>\n",
       "      <th>jobs_posted</th>\n",
       "      <th>past_hires</th>\n",
       "      <th>payment_verification_status</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>snippet_length</th>\n",
       "      <th>skill_and_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1 to 3 months</td>\n",
       "      <td>~011d5dfeb8b13de03e</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[c++, deep-learning, machine-learning, python,...</td>\n",
       "      <td>We need a Deep Learning Research Engineer who ...</td>\n",
       "      <td>Deep Learning Research Engineer</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>2</td>\n",
       "      <td>1571</td>\n",
       "      <td>[[0.959040781435]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>100.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~0110ffd500c79812a5</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[]</td>\n",
       "      <td>Looking for a developer with machine learning ...</td>\n",
       "      <td>Machine Learning on Images</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>[[0.890411138648]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 to 6 months</td>\n",
       "      <td>~0177540d314299aa38</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[]</td>\n",
       "      <td>2+ years of experience with Big Data technolog...</td>\n",
       "      <td>Graph Theory Expert</td>\n",
       "      <td>Less than 10 hrs/week</td>\n",
       "      <td>Israel</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>7</td>\n",
       "      <td>337</td>\n",
       "      <td>[[0.788956111668]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>500.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~01a945fe2e0b69af48</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[]</td>\n",
       "      <td>We are an online eCommerce store. We need some...</td>\n",
       "      <td>Azure Machine Learning Specialist*​</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>3.959637</td>\n",
       "      <td>196</td>\n",
       "      <td>123</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>64</td>\n",
       "      <td>459</td>\n",
       "      <td>[[0.753659023392]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1 to 3 months</td>\n",
       "      <td>~01f5a59f6888037b60</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[c++, deep-learning, machine-learning, python-...</td>\n",
       "      <td>RESPONSIBILITIESImplement newest deep learning...</td>\n",
       "      <td>Deep Learning Intern</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>2</td>\n",
       "      <td>1044</td>\n",
       "      <td>[[0.747069648267]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~01b06be2766a469808</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[accounting, blockchain, process-architect]</td>\n",
       "      <td>Need someone with in-depth knowledge of Blockc...</td>\n",
       "      <td>Analyse différent public blockchain technologi...</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>Turks and Caicos Islands</td>\n",
       "      <td>4.997403</td>\n",
       "      <td>112</td>\n",
       "      <td>72</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>41</td>\n",
       "      <td>286</td>\n",
       "      <td>[[0.727636893021]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 1 month</td>\n",
       "      <td>~01d7c25065dbcd4d6e</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[artificial-neural-networks, cuda, machine-lea...</td>\n",
       "      <td>Looking for an experienced deep learning devel...</td>\n",
       "      <td>tomato leaf disease classification problem usi...</td>\n",
       "      <td>Less than 10 hrs/week</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>[[0.698875009122]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 to 6 months</td>\n",
       "      <td>~01a538d78ee8f56158</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[data-analysis, data-science]</td>\n",
       "      <td>We seek a Data Scientist at our Boston-based p...</td>\n",
       "      <td>Data Scientist - Contractor</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>1645</td>\n",
       "      <td>[[0.687758297939]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~01ec666c5c918989f3</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[artificial-intelligence, machine-learning, pr...</td>\n",
       "      <td>Looking for a programmer with a deep \"applicat...</td>\n",
       "      <td>Financial application developer (architecture ...</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>[[0.655735334578]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~015f8de2b325ec10ac</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[]</td>\n",
       "      <td>BackgroundThere is currently a great deal of a...</td>\n",
       "      <td>Evaluation project to create an example image ...</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>0</td>\n",
       "      <td>874</td>\n",
       "      <td>[[0.650511847954]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 1 week</td>\n",
       "      <td>~018599bf18e98b5fcf</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[machine-learning, python, r]</td>\n",
       "      <td>Hello, I am an Data engineer with 14 years of ...</td>\n",
       "      <td>I am looking for some on to teach me Machine L...</td>\n",
       "      <td>10-30 hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>[[0.646279792026]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 to 6 months</td>\n",
       "      <td>~01aa357e3c15adc4cc</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[computer-vision, d3.js, data-visualization, d...</td>\n",
       "      <td>Looking to discuss particular approaches to al...</td>\n",
       "      <td>Machine Learning Algorithm Development - Image...</td>\n",
       "      <td>10-30 hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>3153</td>\n",
       "      <td>[[0.626328044965]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~01253dea4412023d30</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[artificial-neural-networks, data-analysis, da...</td>\n",
       "      <td>Machine learning and artificial intelligence i...</td>\n",
       "      <td>Data scientists</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>India</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>[[0.621176762183]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>500.0</td>\n",
       "      <td>None</td>\n",
       "      <td>~016048589d777530fc</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[data-scraping, machine-learning, natural-lang...</td>\n",
       "      <td>Looking for a someone to help parse through th...</td>\n",
       "      <td>Machine Learning/NLP/Scraping</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>4.975502</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>18</td>\n",
       "      <td>191</td>\n",
       "      <td>[[0.612315522609]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 1 month</td>\n",
       "      <td>~01fd31d49aaa00df2e</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[machine-learning, mathematics, statistics]</td>\n",
       "      <td>I am currently planning to write an essay on N...</td>\n",
       "      <td>Seeking machine learning expert to assist with...</td>\n",
       "      <td>10-30 hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>1</td>\n",
       "      <td>484</td>\n",
       "      <td>[[0.604169688369]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 to 6 months</td>\n",
       "      <td>~014efe95bb2e534ce0</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[machine-learning, python, r]</td>\n",
       "      <td>Necessary - 0. Minimum 4 years of ANALYTICS ex...</td>\n",
       "      <td>Seasoned and Experienced Data Scientists</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>India</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>585</td>\n",
       "      <td>[[0.597587993803]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 1 month</td>\n",
       "      <td>~01fcc7f3169c76ec24</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[machine-learning, python]</td>\n",
       "      <td>I am looking for some urgent work to work on p...</td>\n",
       "      <td>Machine Learning - Image Analysis</td>\n",
       "      <td>Less than 10 hrs/week</td>\n",
       "      <td>France</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>[[0.586426124755]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>More than 6 months</td>\n",
       "      <td>~0130406bd729d9aeda</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[.net-compact-framework, asp.net, c#, javascri...</td>\n",
       "      <td>Requirements:\\r5+ years of prior professional ...</td>\n",
       "      <td>Senior .NET/SQL developer</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>4.459549</td>\n",
       "      <td>129</td>\n",
       "      <td>93</td>\n",
       "      <td>VERIFIED</td>\n",
       "      <td>55</td>\n",
       "      <td>1010</td>\n",
       "      <td>[[0.585316545841]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Less than 1 month</td>\n",
       "      <td>~013da2a12d25dc4f40</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[data-analysis, data-mining, machine-learning]</td>\n",
       "      <td>We are looking for a data scientist who has do...</td>\n",
       "      <td>Machine learning for churn prediction</td>\n",
       "      <td>Less than 10 hrs/week</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>[[0.580186624651]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3 to 6 months</td>\n",
       "      <td>~01996d1b3732e42885</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>[c++, machine-learning, natural-language-proce...</td>\n",
       "      <td>Looking for an experienced data scientist with...</td>\n",
       "      <td>NLP and machine learning data scientist</td>\n",
       "      <td>30+ hrs/week</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>[[0.579913651586]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget            duration                   id job_type  \\\n",
       "660      0.0       1 to 3 months  ~011d5dfeb8b13de03e   Hourly   \n",
       "2395   100.0                None  ~0110ffd500c79812a5    Fixed   \n",
       "2573     0.0       3 to 6 months  ~0177540d314299aa38   Hourly   \n",
       "2281   500.0                None  ~01a945fe2e0b69af48    Fixed   \n",
       "659      0.0       1 to 3 months  ~01f5a59f6888037b60   Hourly   \n",
       "1240  2000.0                None  ~01b06be2766a469808    Fixed   \n",
       "2666     0.0   Less than 1 month  ~01d7c25065dbcd4d6e   Hourly   \n",
       "2030     0.0       3 to 6 months  ~01a538d78ee8f56158   Hourly   \n",
       "1261     5.0                None  ~01ec666c5c918989f3    Fixed   \n",
       "2451  1000.0                None  ~015f8de2b325ec10ac    Fixed   \n",
       "1626     0.0    Less than 1 week  ~018599bf18e98b5fcf   Hourly   \n",
       "1977     0.0       3 to 6 months  ~01aa357e3c15adc4cc   Hourly   \n",
       "2081  9000.0                None  ~01253dea4412023d30    Fixed   \n",
       "376    500.0                None  ~016048589d777530fc    Fixed   \n",
       "2748     0.0   Less than 1 month  ~01fd31d49aaa00df2e   Hourly   \n",
       "578      0.0       3 to 6 months  ~014efe95bb2e534ce0   Hourly   \n",
       "598      0.0   Less than 1 month  ~01fcc7f3169c76ec24   Hourly   \n",
       "2798     0.0  More than 6 months  ~0130406bd729d9aeda   Hourly   \n",
       "503      0.0   Less than 1 month  ~013da2a12d25dc4f40   Hourly   \n",
       "386      0.0       3 to 6 months  ~01996d1b3732e42885   Hourly   \n",
       "\n",
       "                                                 skills  \\\n",
       "660   [c++, deep-learning, machine-learning, python,...   \n",
       "2395                                                 []   \n",
       "2573                                                 []   \n",
       "2281                                                 []   \n",
       "659   [c++, deep-learning, machine-learning, python-...   \n",
       "1240        [accounting, blockchain, process-architect]   \n",
       "2666  [artificial-neural-networks, cuda, machine-lea...   \n",
       "2030                      [data-analysis, data-science]   \n",
       "1261  [artificial-intelligence, machine-learning, pr...   \n",
       "2451                                                 []   \n",
       "1626                      [machine-learning, python, r]   \n",
       "1977  [computer-vision, d3.js, data-visualization, d...   \n",
       "2081  [artificial-neural-networks, data-analysis, da...   \n",
       "376   [data-scraping, machine-learning, natural-lang...   \n",
       "2748        [machine-learning, mathematics, statistics]   \n",
       "578                       [machine-learning, python, r]   \n",
       "598                          [machine-learning, python]   \n",
       "2798  [.net-compact-framework, asp.net, c#, javascri...   \n",
       "503      [data-analysis, data-mining, machine-learning]   \n",
       "386   [c++, machine-learning, natural-language-proce...   \n",
       "\n",
       "                                                snippet  \\\n",
       "660   We need a Deep Learning Research Engineer who ...   \n",
       "2395  Looking for a developer with machine learning ...   \n",
       "2573  2+ years of experience with Big Data technolog...   \n",
       "2281  We are an online eCommerce store. We need some...   \n",
       "659   RESPONSIBILITIESImplement newest deep learning...   \n",
       "1240  Need someone with in-depth knowledge of Blockc...   \n",
       "2666  Looking for an experienced deep learning devel...   \n",
       "2030  We seek a Data Scientist at our Boston-based p...   \n",
       "1261  Looking for a programmer with a deep \"applicat...   \n",
       "2451  BackgroundThere is currently a great deal of a...   \n",
       "1626  Hello, I am an Data engineer with 14 years of ...   \n",
       "1977  Looking to discuss particular approaches to al...   \n",
       "2081  Machine learning and artificial intelligence i...   \n",
       "376   Looking for a someone to help parse through th...   \n",
       "2748  I am currently planning to write an essay on N...   \n",
       "578   Necessary - 0. Minimum 4 years of ANALYTICS ex...   \n",
       "598   I am looking for some urgent work to work on p...   \n",
       "2798  Requirements:\\r5+ years of prior professional ...   \n",
       "503   We are looking for a data scientist who has do...   \n",
       "386   Looking for an experienced data scientist with...   \n",
       "\n",
       "                                                  title  \\\n",
       "660                     Deep Learning Research Engineer   \n",
       "2395                         Machine Learning on Images   \n",
       "2573                                Graph Theory Expert   \n",
       "2281                Azure Machine Learning Specialist*​   \n",
       "659                                Deep Learning Intern   \n",
       "1240  Analyse différent public blockchain technologi...   \n",
       "2666  tomato leaf disease classification problem usi...   \n",
       "2030                        Data Scientist - Contractor   \n",
       "1261  Financial application developer (architecture ...   \n",
       "2451  Evaluation project to create an example image ...   \n",
       "1626  I am looking for some on to teach me Machine L...   \n",
       "1977  Machine Learning Algorithm Development - Image...   \n",
       "2081                                    Data scientists   \n",
       "376                       Machine Learning/NLP/Scraping   \n",
       "2748  Seeking machine learning expert to assist with...   \n",
       "578            Seasoned and Experienced Data Scientists   \n",
       "598                   Machine Learning - Image Analysis   \n",
       "2798                          Senior .NET/SQL developer   \n",
       "503               Machine learning for churn prediction   \n",
       "386             NLP and machine learning data scientist   \n",
       "\n",
       "                   workload                   country  feedback  jobs_posted  \\\n",
       "660            30+ hrs/week            United Kingdom  5.000000           11   \n",
       "2395           30+ hrs/week             United States  0.000000            2   \n",
       "2573  Less than 10 hrs/week                    Israel  5.000000           21   \n",
       "2281           30+ hrs/week                  Barbados  3.959637          196   \n",
       "659            30+ hrs/week            United Kingdom  5.000000           11   \n",
       "1240           30+ hrs/week  Turks and Caicos Islands  4.997403          112   \n",
       "2666  Less than 10 hrs/week               South Korea  0.000000            1   \n",
       "2030           30+ hrs/week             United States  0.000000            1   \n",
       "1261           30+ hrs/week             United States  0.000000            1   \n",
       "2451           30+ hrs/week             United States  0.000000            2   \n",
       "1626         10-30 hrs/week             United States  0.000000            2   \n",
       "1977         10-30 hrs/week             United States  0.000000            3   \n",
       "2081           30+ hrs/week                     India  0.000000            5   \n",
       "376            30+ hrs/week             United States  4.975502           51   \n",
       "2748         10-30 hrs/week             United States  5.000000            6   \n",
       "578            30+ hrs/week                     India  0.000000            9   \n",
       "598   Less than 10 hrs/week                    France  0.000000            3   \n",
       "2798           30+ hrs/week             United States  4.459549          129   \n",
       "503   Less than 10 hrs/week                   Armenia  0.000000            1   \n",
       "386            30+ hrs/week             United States  0.000000            1   \n",
       "\n",
       "      past_hires payment_verification_status  reviews_count  snippet_length  \\\n",
       "660            4                    VERIFIED              2            1571   \n",
       "2395           1                    VERIFIED              0             222   \n",
       "2573          15                    VERIFIED              7             337   \n",
       "2281         123                    VERIFIED             64             459   \n",
       "659            4                    VERIFIED              2            1044   \n",
       "1240          72                    VERIFIED             41             286   \n",
       "2666           0                    VERIFIED              0             223   \n",
       "2030           0                     UNKNOWN              0            1645   \n",
       "1261           0                     UNKNOWN              0             628   \n",
       "2451           2                    VERIFIED              0             874   \n",
       "1626           0                     UNKNOWN              0             225   \n",
       "1977           0                        None              0            3153   \n",
       "2081           0                     UNKNOWN              0             156   \n",
       "376           49                    VERIFIED             18             191   \n",
       "2748           2                    VERIFIED              1             484   \n",
       "578            0                     UNKNOWN              0             585   \n",
       "598            0                     UNKNOWN              0             195   \n",
       "2798          93                    VERIFIED             55            1010   \n",
       "503            0                        None              0             365   \n",
       "386            0                     UNKNOWN              0             230   \n",
       "\n",
       "     skill_and_similarity  \n",
       "660    [[0.959040781435]]  \n",
       "2395   [[0.890411138648]]  \n",
       "2573   [[0.788956111668]]  \n",
       "2281   [[0.753659023392]]  \n",
       "659    [[0.747069648267]]  \n",
       "1240   [[0.727636893021]]  \n",
       "2666   [[0.698875009122]]  \n",
       "2030   [[0.687758297939]]  \n",
       "1261   [[0.655735334578]]  \n",
       "2451   [[0.650511847954]]  \n",
       "1626   [[0.646279792026]]  \n",
       "1977   [[0.626328044965]]  \n",
       "2081   [[0.621176762183]]  \n",
       "376    [[0.612315522609]]  \n",
       "2748   [[0.604169688369]]  \n",
       "578    [[0.597587993803]]  \n",
       "598    [[0.586426124755]]  \n",
       "2798   [[0.585316545841]]  \n",
       "503    [[0.580186624651]]  \n",
       "386    [[0.579913651586]]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_blurb = just_blurbs_long[\"dev_blurb\"].iloc[100]\n",
    "ultimate_matching_algorithm(jobs, ex_blurb, profile_skills = [\"java\", \"c++\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
